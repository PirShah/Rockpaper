# Step 1: Import required libraries
import pandas as pd
import numpy as np
import tensorflow as tf
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
import matplotlib.pyplot as plt

# Step 2: Load the dataset
df = pd.read_csv('/content/insurance.csv')  # Adjust path if needed

# Step 3: Convert categorical columns to numeric using one-hot encoding
df = pd.get_dummies(df, columns=['sex', 'smoker', 'region'], drop_first=True)

# Step 4: Separate features and target
X = df.drop('expenses', axis=1)
y = df['expenses']

# Step 5: Split the data (80% train, 20% test)
train_dataset, test_dataset, train_labels, test_labels = train_test_split(
    X, y, test_size=0.2, random_state=42
)

# Step 6: Scale the features using StandardScaler
scaler = StandardScaler()
train_dataset = scaler.fit_transform(train_dataset)
test_dataset = scaler.transform(test_dataset)

# Step 7: Build the neural network model
model = tf.keras.Sequential([
    tf.keras.layers.Dense(64, activation='relu', input_shape=(train_dataset.shape[1],)),
    tf.keras.layers.Dense(64, activation='relu'),
    tf.keras.layers.Dense(1)  # Output layer for regression
])

# Step 8: Compile the model
model.compile(optimizer='adam', loss='mae', metrics=['mae'])

# Step 9: Train the model
model.fit(train_dataset, train_labels, epochs=100, validation_split=0.2, verbose=0)

# Step 10: Evaluate the model
loss, mae = model.evaluate(test_dataset, test_labels)
print(f"\nâœ… Mean Absolute Error (MAE): ${mae:.2f}")

# Step 11: Predict and plot
predictions = model.predict(test_dataset).flatten()

plt.figure(figsize=(8, 6))
plt.scatter(test_labels, predictions)
plt.xlabel("True Values ($)")
plt.ylabel("Predicted Values ($)")
plt.title("Healthcare Cost Prediction")
plt.plot([0, max(test_labels)], [0, max(test_labels)], color='red')  # ideal line
plt.grid(True)
plt.show()
