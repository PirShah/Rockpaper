# Step 1: Import required libraries
import pandas as pd
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.naive_bayes import MultinomialNB
from sklearn.pipeline import make_pipeline
from sklearn.model_selection import train_test_split

# Step 2: Load the dataset
# Assume the dataset is already loaded in `train_data` and `test_data` as per the challenge
# Example fallback loading:
# data = pd.read_csv('/content/spam.csv', encoding='latin-1')[['v1', 'v2']]
# data.columns = ['label', 'message']
# train_data, test_data = train_test_split(data, test_size=0.2, random_state=42)

# Sample placeholder:
# train_data = pd.DataFrame({'label': [...], 'message': [...]})
# test_data = pd.DataFrame({'label': [...], 'message': [...]})

# Step 3: Prepare the model
model = make_pipeline(TfidfVectorizer(), MultinomialNB())

# Step 4: Train the model
model.fit(train_data['message'], train_data['label'])

# Step 5: Define prediction function
def predict_message(message):
    prediction_prob = model.predict_proba([message])[0]
    spam_index = list(model.classes_).index("spam")
    ham_index = list(model.classes_).index("ham")
    
    # spam probability
    spam_prob = prediction_prob[spam_index]
    
    label = "spam" if spam_prob > 0.5 else "ham"
    return [round(spam_prob, 2), label]
